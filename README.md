# vLLMConfig

A local environment setup framework designed for configuring and managing large language models (LLMs) using VLLM. This project simplifies the deployment process by providing efficient and scalable settings tailored for on-premise inference tasks, ensuring optimal performance and data security.

---

## ç°¡ä»‹

é€™ä»½å°ˆæ¡ˆæä¾›äº†ä¸€éµéƒ¨ç½²çš„å®¹å™¨åŒ–è§£æ±ºæ–¹æ¡ˆï¼Œå°‡ Hugging Face (HF) çš„ LLM æ¨¡å‹åŒ…åˆ° Docker æ˜ åƒæª”ä¸­ï¼Œä¸¦é‡å°å°é–‰ç¶²è·¯ç’°å¢ƒå„ªåŒ–ã€‚

- é è¨­æ”¯æŒ vLLM çš„ OpenLLM API æ ¼å¼ã€‚
- å°æ¨ç†æ™‚çš„ API å’Œå®¹å™¨ç©©å®šæ€§é€²è¡Œäº†å¿…è¦çš„èª¿æ•´ã€‚

---

## ç‰¹é»

- **ğŸ› ï¸ ä¸€éµæ¨¡å‹åŒ…è£¹**ï¼šå¿«é€Ÿå°‡ Hugging Face ä¸Šçš„æ¨¡å‹ä¸‹è¼‰ä¸¦åŒ…è£¹åˆ°æ˜ åƒæª”ä¸­ï¼Œé©ç”¨æ–¼ç„¡æ³•ç›´æ¥è¨ªå•å¤–éƒ¨ç¶²è·¯çš„å°é–‰ç’°å¢ƒã€‚
- **ğŸŒ é è¨­ OpenLLM API æ ¼å¼**ï¼šæ”¯æŒèˆ‡ vLLM API çš„å³æ™‚é›†æˆï¼Œç„¡éœ€é¡å¤–è¨­å®šã€‚
- **ğŸš¦ å®¹å™¨ç©©å®šæ€§ä¿éšœ**ï¼šé…ç½®ç›¸é—œåƒæ•¸ï¼Œé¿å…å®¹å™¨å› éé‡è«‹æ±‚å°è‡´çš„æœå‹™ä¸­æ–·ã€‚

---

## æ–‡ä»¶çµæ§‹

```
.
â”œâ”€â”€ Dockerfile              # Image æ‰“åŒ…æ–‡ä»¶
â”œâ”€â”€ docker-compose.yml      # å•Ÿç”¨åƒæ•¸è¨­å®š
â””â”€â”€ README.md               # èªªæ˜æ–‡ä»¶
```
